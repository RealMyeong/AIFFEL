{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VTMgqZNLcgOb_IeB_YuFyP_K2Qa78--h",
      "authorship_tag": "ABX9TyMTqHSAJxHJFAKYREbxMjCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RealMyeong/Aiffel_Exploration/blob/main/EX_BS2_project14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. 프로젝트 : 한국어 데이터로 챗봇 만들기\n"
      ],
      "metadata": {
        "id": "5Hg4gN4vEDOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1. 데이터 수집하기"
      ],
      "metadata": {
        "id": "5P_pXOr5EIvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 모듈 임포트 하기\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "Dn3rJlPxEr9G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2. 데이터 전처리하기"
      ],
      "metadata": {
        "id": "MdeqUlfUELlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 불러오기\n",
        "  - Data description.\n",
        "    - 챗봇 트레이닝용 문답 페어 11,876개\n",
        "    - 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링"
      ],
      "metadata": {
        "id": "v5JOzhApGkE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/AIFFEL/EX/14_chatbot/project/ChatbotData .csv'\n",
        "data = pd.read_csv(data_path)\n",
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "cwYeAmqcGjdX",
        "outputId": "d77ca3ee-2a13-4cb1-a1e4-0a18e42c85ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Q                   A  label\n",
              "0                   12시 땡!          하루가 또 가네요.      0\n",
              "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
              "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
              "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
              "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
              "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
              "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
              "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6585942d-b05b-419d-86eb-10678bb4fade\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
              "      <td>잘 모르고 있을 수도 있어요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6585942d-b05b-419d-86eb-10678bb4fade')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6585942d-b05b-419d-86eb-10678bb4fade button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6585942d-b05b-419d-86eb-10678bb4fade');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "0Oxja8tJG3wN",
        "outputId": "934fee12-4ea9-4e07-ed76-1dc819cb1318"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Q                                            A  \\\n",
              "11813   회사에 좋아하는 남자가 생겼어 어떡하지?                              사랑하기 힘든 관계인가봐요.   \n",
              "11814   회사에서 어떤 사람이랑 자꾸 눈 마추쳐.                      눈 마주치는 게 우연인지 잘 살펴 보세요.   \n",
              "11815      회식 중이라고 하는데 연락이 안돼.  정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.   \n",
              "11816        회식하는데 나만 챙겨줘. 썸임?          호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.   \n",
              "11817            후회 없이 사랑하고 싶어                                진심으로 다가가 보세요.   \n",
              "11818           훔쳐보는 것도 눈치 보임.                           티가 나니까 눈치가 보이는 거죠!   \n",
              "11819           훔쳐보는 것도 눈치 보임.                                훔쳐보는 거 티나나봐요.   \n",
              "11820              흑기사 해주는 짝남.                                       설렜겠어요.   \n",
              "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?                     잘 헤어질 수 있는 사이 여부인 거 같아요.   \n",
              "11822               힘들어서 결혼할까봐                           도피성 결혼은 하지 않길 바라요.   \n",
              "\n",
              "       label  \n",
              "11813      2  \n",
              "11814      2  \n",
              "11815      2  \n",
              "11816      2  \n",
              "11817      2  \n",
              "11818      2  \n",
              "11819      2  \n",
              "11820      2  \n",
              "11821      2  \n",
              "11822      2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f48b6427-59f6-487b-a975-8508a6a8a367\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11813</th>\n",
              "      <td>회사에 좋아하는 남자가 생겼어 어떡하지?</td>\n",
              "      <td>사랑하기 힘든 관계인가봐요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11814</th>\n",
              "      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐.</td>\n",
              "      <td>눈 마주치는 게 우연인지 잘 살펴 보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11815</th>\n",
              "      <td>회식 중이라고 하는데 연락이 안돼.</td>\n",
              "      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11816</th>\n",
              "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
              "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11817</th>\n",
              "      <td>후회 없이 사랑하고 싶어</td>\n",
              "      <td>진심으로 다가가 보세요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11818</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
              "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11819</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
              "      <td>훔쳐보는 거 티나나봐요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11820</th>\n",
              "      <td>흑기사 해주는 짝남.</td>\n",
              "      <td>설렜겠어요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11821</th>\n",
              "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
              "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11822</th>\n",
              "      <td>힘들어서 결혼할까봐</td>\n",
              "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f48b6427-59f6-487b-a975-8508a6a8a367')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f48b6427-59f6-487b-a975-8508a6a8a367 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f48b6427-59f6-487b-a975-8508a6a8a367');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81BXr-5vK-bP",
        "outputId": "cc871629-8de3-40cc-fb84-a2a445f9ca3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11823 entries, 0 to 11822\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Q       11823 non-null  object\n",
            " 1   A       11823 non-null  object\n",
            " 2   label   11823 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 277.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결측치 확인"
      ],
      "metadata": {
        "id": "KfIhsqHFLRzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV4bHsnGLTEb",
        "outputId": "4a51e8a8-c330-47e6-cfd8-acaeb876b341"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Q        0\n",
              "A        0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 전처리 함수 정의\n",
        "  - 구두점 제거\n"
      ],
      "metadata": {
        "id": "L4K6LWpEHtGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 함수\n",
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.strip()\n",
        "\n",
        "  # 단어와 구두점 사이의 거리를 만듦\n",
        "  sentence = re.sub(r\"([?.!,~])\", r\" \\1\", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "  # (ㄱ-ㅎ, ㅏ-ㅣ, 가-힣, '.', '?', '!', ',')를 제외한 모든 문자를 공백인 ' '로 대체합니다\n",
        "  sentence = re.sub(r\"[^가-힣?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "bsexz1g9Ho9Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q, A라벨 별로 전처리 함수 적용해서 전처리 진행해줌"
      ],
      "metadata": {
        "id": "0zyy3u6uLZHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Q'] = data['Q'].apply(lambda x : preprocess_sentence(x))\n",
        "data['A'] = data['A'].apply(lambda x : preprocess_sentence(x))"
      ],
      "metadata": {
        "id": "pciH63GzJ-vD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "K54_nlkQMDlS",
        "outputId": "e0846256-cc03-4d99-ff87-4849093decec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Q                    A  label\n",
              "0                시 땡 !          하루가 또 가네요 .      0\n",
              "1           지망 학교 떨어졌어           위로해 드립니다 .      0\n",
              "2          박 일 놀러가고 싶다         여행은 언제나 좋죠 .      0\n",
              "3       박 일 정도 놀러가고 싶다         여행은 언제나 좋죠 .      0\n",
              "4                  심하네          눈살이 찌푸려지죠 .      0\n",
              "5              카드 망가졌어  다시 새로 사는 게 마음 편해요 .      0\n",
              "6                카드 안돼  다시 새로 사는 게 마음 편해요 .      0\n",
              "7             맞팔 왜 안하지    잘 모르고 있을 수도 있어요 .      0\n",
              "8  시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요 .      0\n",
              "9        시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요 .      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcaefd1e-ab99-402a-ac1a-562f3a3fd5f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>시 땡 !</td>\n",
              "      <td>하루가 또 가네요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>박 일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>박 일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>심하네</td>\n",
              "      <td>눈살이 찌푸려지죠 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>맞팔 왜 안하지</td>\n",
              "      <td>잘 모르고 있을 수도 있어요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcaefd1e-ab99-402a-ac1a-562f3a3fd5f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcaefd1e-ab99-402a-ac1a-562f3a3fd5f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcaefd1e-ab99-402a-ac1a-562f3a3fd5f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "uYcKrRWwORs-",
        "outputId": "e853cf22-82e3-45f9-92c7-565c905c7e30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Q  \\\n",
              "11813   회사에 좋아하는 남자가 생겼어 어떡하지 ?   \n",
              "11814   회사에서 어떤 사람이랑 자꾸 눈 마추쳐 .   \n",
              "11815      회식 중이라고 하는데 연락이 안돼 .   \n",
              "11816       회식하는데 나만 챙겨줘 . 썸임 ?   \n",
              "11817             후회 없이 사랑하고 싶어   \n",
              "11818           훔쳐보는 것도 눈치 보임 .   \n",
              "11819           훔쳐보는 것도 눈치 보임 .   \n",
              "11820              흑기사 해주는 짝남 .   \n",
              "11821  힘든 연애 좋은 연애라는게 무슨 차이일까 ?   \n",
              "11822                힘들어서 결혼할까봐   \n",
              "\n",
              "                                                   A  label  \n",
              "11813                               사랑하기 힘든 관계인가봐요 .      2  \n",
              "11814                       눈 마주치는 게 우연인지 잘 살펴 보세요 .      2  \n",
              "11815  정신 없이 바쁠지도 몰라요 . 조금만 더 기다려보고 물어보는게 좋을 것 같아요 .      2  \n",
              "11816          호감이 있을 수도 있어요 . 그렇지만 조금 더 상황을 지켜보세요 .      2  \n",
              "11817                                 진심으로 다가가 보세요 .      2  \n",
              "11818                            티가 나니까 눈치가 보이는 거죠 !      2  \n",
              "11819                                 훔쳐보는 거 티나나봐요 .      2  \n",
              "11820                                        설렜겠어요 .      2  \n",
              "11821                      잘 헤어질 수 있는 사이 여부인 거 같아요 .      2  \n",
              "11822                            도피성 결혼은 하지 않길 바라요 .      2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7707e05e-3812-4fc9-add1-0ac8eb22d15a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11813</th>\n",
              "      <td>회사에 좋아하는 남자가 생겼어 어떡하지 ?</td>\n",
              "      <td>사랑하기 힘든 관계인가봐요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11814</th>\n",
              "      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐 .</td>\n",
              "      <td>눈 마주치는 게 우연인지 잘 살펴 보세요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11815</th>\n",
              "      <td>회식 중이라고 하는데 연락이 안돼 .</td>\n",
              "      <td>정신 없이 바쁠지도 몰라요 . 조금만 더 기다려보고 물어보는게 좋을 것 같아요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11816</th>\n",
              "      <td>회식하는데 나만 챙겨줘 . 썸임 ?</td>\n",
              "      <td>호감이 있을 수도 있어요 . 그렇지만 조금 더 상황을 지켜보세요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11817</th>\n",
              "      <td>후회 없이 사랑하고 싶어</td>\n",
              "      <td>진심으로 다가가 보세요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11818</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임 .</td>\n",
              "      <td>티가 나니까 눈치가 보이는 거죠 !</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11819</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임 .</td>\n",
              "      <td>훔쳐보는 거 티나나봐요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11820</th>\n",
              "      <td>흑기사 해주는 짝남 .</td>\n",
              "      <td>설렜겠어요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11821</th>\n",
              "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까 ?</td>\n",
              "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11822</th>\n",
              "      <td>힘들어서 결혼할까봐</td>\n",
              "      <td>도피성 결혼은 하지 않길 바라요 .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7707e05e-3812-4fc9-add1-0ac8eb22d15a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7707e05e-3812-4fc9-add1-0ac8eb22d15a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7707e05e-3812-4fc9-add1-0ac8eb22d15a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리가 잘 된 것을 볼 수 있음"
      ],
      "metadata": {
        "id": "CDwI14yWOYWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터에서 라벨은 딱히 상관이 없어 보인다.\n",
        "\n",
        " 라벨 부분은 지우고 Q, A만 사용"
      ],
      "metadata": {
        "id": "GvGmLxlsPBev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop('label', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "EmzmsrabPyMd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SzIRwOSvP-Pb",
        "outputId": "77ef9bd5-5a4b-43f3-abbd-4bea96faa3c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Q             A\n",
              "0           시 땡 !   하루가 또 가네요 .\n",
              "1      지망 학교 떨어졌어    위로해 드립니다 .\n",
              "2     박 일 놀러가고 싶다  여행은 언제나 좋죠 .\n",
              "3  박 일 정도 놀러가고 싶다  여행은 언제나 좋죠 .\n",
              "4             심하네   눈살이 찌푸려지죠 ."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90d237ea-ee54-4dc3-88c3-d47468205a23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>시 땡 !</td>\n",
              "      <td>하루가 또 가네요 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>박 일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>박 일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>심하네</td>\n",
              "      <td>눈살이 찌푸려지죠 .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90d237ea-ee54-4dc3-88c3-d47468205a23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90d237ea-ee54-4dc3-88c3-d47468205a23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90d237ea-ee54-4dc3-88c3-d47468205a23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문, 답변 리스트 생성\n",
        "question = list(data['Q'])\n",
        "answer = list(data['A'])"
      ],
      "metadata": {
        "id": "PWj7C9iaQ81-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3. SubwordTextEncoder 사용하기\n",
        "\n",
        "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해보세요."
      ],
      "metadata": {
        "id": "wYzrWIt1EO1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문과 답변 데이터에 대해 Vacabulary 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(question + answer, target_vocab_size=2**13)\n"
      ],
      "metadata": {
        "id": "JvmUf_GfRJSP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".subwords 를 통해 토큰화된 서브워드 확인"
      ],
      "metadata": {
        "id": "Ut4Wx-W5Rj2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.subwords[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuXgF0IpRbOn",
        "outputId": "43ca8303-69c9-492f-9ef9-3b9cebffd793"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' .', ' ?', '거예요', '수_', '게_', '너무_', '더_', '거_', '는_', '좋아하는_', '이_', '을_', '잘_', '도_', ' . ', '고_', '요', '것_', '많이_', '안_']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원래 문장과 정수 인코딩 진행한 결과 확인"
      ],
      "metadata": {
        "id": "tGEHXgNuRvqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(question[10])\n",
        "a = tokenizer.encode(question[10])\n",
        "print(f'정수 인코딩 결과 : {a}')\n",
        "print(f'다시 디코딩 : {tokenizer.decode(a)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkzOA1H6R7tV",
        "outputId": "c87f8493-57bd-418e-dbcd-b927ef6e25a3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "보면 나만 빼고 다 행복해보여\n",
            "정수 인코딩 결과 : [485, 196, 2967, 45, 3805]\n",
            "다시 디코딩 : 보면 나만 빼고 다 행복해보여\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어장 크기 확인"
      ],
      "metadata": {
        "id": "fekWfK9MSxHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqAWGPH-Swxd",
        "outputId": "b77a9734-2319-4ba6-fc69-8041153167f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8127"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 단어와 매핑된 정수 확인"
      ],
      "metadata": {
        "id": "RaCts52bS54z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ts in a:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmKL5PFOS8lh",
        "outputId": "52b3d54f-5c86-41ff-fda5-74c84d32daa6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "485 ----> 보면 \n",
            "196 ----> 나만 \n",
            "2967 ----> 빼고 \n",
            "45 ----> 다 \n",
            "3805 ----> 행복해보여\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "시작 토큰과 종료 토큰도 단어장에 추가하여 정수 인코딩 진행"
      ],
      "metadata": {
        "id": "IPFOjp4sTWVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수 부여\n",
        "start_token = [tokenizer.vocab_size]\n",
        "end_token = [tokenizer.vocab_size + 1]\n",
        "print(f'시작 토큰 번호: {start_token}, 종료 토큰 번호 : {end_token}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li0hec5hTbw8",
        "outputId": "8a395276-4074-47b7-f8cb-7aa41343763e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시작 토큰 번호: [8127], 종료 토큰 번호 : [8128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vacab_size 시작, 종료 토큰 고려하여 재설정\n",
        "vocab_size = tokenizer.vocab_size + 2"
      ],
      "metadata": {
        "id": "d172PNZTWdy2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "패딩 진행"
      ],
      "metadata": {
        "id": "ITEGhUiST47E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문 데이터 길이들\n",
        "q_word_len = [len(x) for x in question ]\n",
        "# 답변 데이터 길이들\n",
        "a_word_len = [len(x) for x in answer ]\n",
        "\n",
        "# 각각 최대 길이 뽑아봄\n",
        "print(f'질문 최대 길이 : {max(q_word_len)} \\n답변 최대 길이 : {max(a_word_len)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLoqQq7HUIss",
        "outputId": "0fed5655-a099-43e8-d4a0-38fff881d392"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문 최대 길이 : 57 \n",
            "답변 최대 길이 : 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 60 \n",
        "\n",
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = start_token + tokenizer.encode(sentence1) + end_token\n",
        "    sentence2 = start_token + tokenizer.encode(sentence2) + end_token\n",
        "\n",
        "    # MAX_LENGTH 이하인 경우에만 데이터로 사용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # MAX_LENGTH로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "metadata": {
        "id": "pO_1ORCvT62U"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions, answers = tokenize_and_filter(question, answer)\n",
        "print(f'단어장의 크기 : {vocab_size}')\n",
        "print(f'필터링 후의 질문 샘플 개수 : {len(questions)}')\n",
        "print(f'필터링 후의 답변 샘플 개수 : {len(answers)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0HtgTZyWRVl",
        "outputId": "95563598-7c28-49f4-b83d-1e6c89270f6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어장의 크기 : 8129\n",
            "필터링 후의 질문 샘플 개수 : 11823\n",
            "필터링 후의 답변 샘플 개수 : 11823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다. 이 때, 교사 강요를 위해서 answer[:, :-1]를 디코더의 입력값, answer[:, 1:]를 디코더의 레이블로 사용합니다."
      ],
      "metadata": {
        "id": "rC4OKRp0wKQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "buffer_size = 11823\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 따라서 outputs에서는 start_token을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices(({\n",
        "    'inputs' : questions,\n",
        "    'dec_inputs' : answers[:, :-1]\n",
        "},{\n",
        "    'outputs' : answers[:, 1:]\n",
        "}))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(buffer_size)\n",
        "dataset = dataset.batch(batch_size)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "57CK4QogwFwi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4. 모델 구성하기\n",
        "\n",
        "실습 내용을 참고하여 트랜스포머 모델을 구현합니다."
      ],
      "metadata": {
        "id": "8XGaMtxCEbBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "\n",
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "\n",
        "# 패딩 마스크\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "\n",
        "# 룩어헤드 마스크\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n",
        "\n",
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "\n",
        "# 인코더 층 쌓아서 인코더 만들기\n",
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "\n",
        "\n",
        "# 디코더 층을 쌓아서 디코더 만들기\n",
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n"
      ],
      "metadata": {
        "id": "OiefTDsshvb3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 트랜스포머 함수 정의"
      ],
      "metadata": {
        "id": "UO4QH81XxKyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
      ],
      "metadata": {
        "id": "mNz6C7i3xNVK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 생성"
      ],
      "metadata": {
        "id": "wZ4y3NsKxvAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 5 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 256 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.3 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=vocab_size,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5l5CP9nxwct",
        "outputId": "76f78608-42c2-48e7-8063-224bdfec1fe4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    4059904     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    5378304     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8129)   2089153     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,527,361\n",
            "Trainable params: 11,527,361\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실함수\n",
        "\n",
        "---\n",
        "레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다."
      ],
      "metadata": {
        "id": "-DZ5aOna2rKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)\n"
      ],
      "metadata": {
        "id": "oDfUxBDc2x9v"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 커스텀 된 학습률"
      ],
      "metadata": {
        "id": "pKGH6v2U22i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "metadata": {
        "id": "_GfiaKwN24X-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 컴파일"
      ],
      "metadata": {
        "id": "_LNqlnvK2-qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "id": "egHT-srV2_mm"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 훈련"
      ],
      "metadata": {
        "id": "LErIbeym3JyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPOJ-a4x3LHS",
        "outputId": "07608d8d-3ea3-4ab1-da88-2b3185dab708"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "185/185 [==============================] - 41s 127ms/step - loss: 0.9652 - accuracy: 0.0133\n",
            "Epoch 2/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.8013 - accuracy: 0.0200\n",
            "Epoch 3/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.6920 - accuracy: 0.0327\n",
            "Epoch 4/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.6518 - accuracy: 0.0333\n",
            "Epoch 5/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.6249 - accuracy: 0.0340\n",
            "Epoch 6/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.6082 - accuracy: 0.0348\n",
            "Epoch 7/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.5934 - accuracy: 0.0355\n",
            "Epoch 8/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.5796 - accuracy: 0.0361\n",
            "Epoch 9/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.5668 - accuracy: 0.0368\n",
            "Epoch 10/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.5523 - accuracy: 0.0376\n",
            "Epoch 11/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.5385 - accuracy: 0.0383\n",
            "Epoch 12/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.5233 - accuracy: 0.0391\n",
            "Epoch 13/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.5076 - accuracy: 0.0399\n",
            "Epoch 14/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.4912 - accuracy: 0.0408\n",
            "Epoch 15/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.4739 - accuracy: 0.0418\n",
            "Epoch 16/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.4560 - accuracy: 0.0430\n",
            "Epoch 17/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.4382 - accuracy: 0.0445\n",
            "Epoch 18/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.4209 - accuracy: 0.0459\n",
            "Epoch 19/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.4029 - accuracy: 0.0477\n",
            "Epoch 20/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.3864 - accuracy: 0.0495\n",
            "Epoch 21/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.3702 - accuracy: 0.0512\n",
            "Epoch 22/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.3544 - accuracy: 0.0532\n",
            "Epoch 23/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.3372 - accuracy: 0.0552\n",
            "Epoch 24/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.3195 - accuracy: 0.0577\n",
            "Epoch 25/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.3041 - accuracy: 0.0600\n",
            "Epoch 26/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2900 - accuracy: 0.0621\n",
            "Epoch 27/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.2782 - accuracy: 0.0637\n",
            "Epoch 28/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2661 - accuracy: 0.0658\n",
            "Epoch 29/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2566 - accuracy: 0.0673\n",
            "Epoch 30/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2474 - accuracy: 0.0687\n",
            "Epoch 31/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2393 - accuracy: 0.0700\n",
            "Epoch 32/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2319 - accuracy: 0.0716\n",
            "Epoch 33/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2257 - accuracy: 0.0726\n",
            "Epoch 34/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2202 - accuracy: 0.0737\n",
            "Epoch 35/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.2147 - accuracy: 0.0747\n",
            "Epoch 36/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.2092 - accuracy: 0.0759\n",
            "Epoch 37/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.2051 - accuracy: 0.0766\n",
            "Epoch 38/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.2017 - accuracy: 0.0773\n",
            "Epoch 39/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1978 - accuracy: 0.0782\n",
            "Epoch 40/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1948 - accuracy: 0.0787\n",
            "Epoch 41/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1917 - accuracy: 0.0792\n",
            "Epoch 42/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1886 - accuracy: 0.0800\n",
            "Epoch 43/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1860 - accuracy: 0.0805\n",
            "Epoch 44/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1829 - accuracy: 0.0813\n",
            "Epoch 45/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1813 - accuracy: 0.0813\n",
            "Epoch 46/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1793 - accuracy: 0.0818\n",
            "Epoch 47/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1765 - accuracy: 0.0822\n",
            "Epoch 48/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1752 - accuracy: 0.0826\n",
            "Epoch 49/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1721 - accuracy: 0.0832\n",
            "Epoch 50/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1709 - accuracy: 0.0835\n",
            "Epoch 51/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1694 - accuracy: 0.0837\n",
            "Epoch 52/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1675 - accuracy: 0.0840\n",
            "Epoch 53/100\n",
            "185/185 [==============================] - 25s 133ms/step - loss: 0.1662 - accuracy: 0.0843\n",
            "Epoch 54/100\n",
            "185/185 [==============================] - 25s 136ms/step - loss: 0.1643 - accuracy: 0.0846\n",
            "Epoch 55/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1632 - accuracy: 0.0848\n",
            "Epoch 56/100\n",
            "185/185 [==============================] - 24s 129ms/step - loss: 0.1617 - accuracy: 0.0851\n",
            "Epoch 57/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1598 - accuracy: 0.0855\n",
            "Epoch 58/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1592 - accuracy: 0.0857\n",
            "Epoch 59/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1574 - accuracy: 0.0858\n",
            "Epoch 60/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1566 - accuracy: 0.0860\n",
            "Epoch 61/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1550 - accuracy: 0.0864\n",
            "Epoch 62/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1545 - accuracy: 0.0863\n",
            "Epoch 63/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1532 - accuracy: 0.0866\n",
            "Epoch 64/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1523 - accuracy: 0.0867\n",
            "Epoch 65/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1512 - accuracy: 0.0870\n",
            "Epoch 66/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1501 - accuracy: 0.0872\n",
            "Epoch 67/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1489 - accuracy: 0.0874\n",
            "Epoch 68/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1482 - accuracy: 0.0876\n",
            "Epoch 69/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1467 - accuracy: 0.0879\n",
            "Epoch 70/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1466 - accuracy: 0.0879\n",
            "Epoch 71/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1455 - accuracy: 0.0881\n",
            "Epoch 72/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1445 - accuracy: 0.0882\n",
            "Epoch 73/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1446 - accuracy: 0.0880\n",
            "Epoch 74/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1426 - accuracy: 0.0885\n",
            "Epoch 75/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1421 - accuracy: 0.0886\n",
            "Epoch 76/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1417 - accuracy: 0.0886\n",
            "Epoch 77/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1409 - accuracy: 0.0888\n",
            "Epoch 78/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1397 - accuracy: 0.0890\n",
            "Epoch 79/100\n",
            "185/185 [==============================] - 23s 126ms/step - loss: 0.1399 - accuracy: 0.0890\n",
            "Epoch 80/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1389 - accuracy: 0.0892\n",
            "Epoch 81/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1382 - accuracy: 0.0894\n",
            "Epoch 82/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1370 - accuracy: 0.0896\n",
            "Epoch 83/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1371 - accuracy: 0.0895\n",
            "Epoch 84/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1359 - accuracy: 0.0897\n",
            "Epoch 85/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1359 - accuracy: 0.0895\n",
            "Epoch 86/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1349 - accuracy: 0.0898\n",
            "Epoch 87/100\n",
            "185/185 [==============================] - 24s 128ms/step - loss: 0.1345 - accuracy: 0.0898\n",
            "Epoch 88/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1338 - accuracy: 0.0901\n",
            "Epoch 89/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1339 - accuracy: 0.0899\n",
            "Epoch 90/100\n",
            "185/185 [==============================] - 24s 128ms/step - loss: 0.1330 - accuracy: 0.0902\n",
            "Epoch 91/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1324 - accuracy: 0.0900\n",
            "Epoch 92/100\n",
            "185/185 [==============================] - 24s 128ms/step - loss: 0.1317 - accuracy: 0.0903\n",
            "Epoch 93/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1311 - accuracy: 0.0905\n",
            "Epoch 94/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1309 - accuracy: 0.0905\n",
            "Epoch 95/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1303 - accuracy: 0.0904\n",
            "Epoch 96/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1295 - accuracy: 0.0906\n",
            "Epoch 97/100\n",
            "185/185 [==============================] - 23s 127ms/step - loss: 0.1293 - accuracy: 0.0907\n",
            "Epoch 98/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1292 - accuracy: 0.0907\n",
            "Epoch 99/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1289 - accuracy: 0.0907\n",
            "Epoch 100/100\n",
            "185/185 [==============================] - 24s 127ms/step - loss: 0.1280 - accuracy: 0.0910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdf981c6350>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5. 모델 평가하기\n",
        "\n",
        "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다."
      ],
      "metadata": {
        "id": "_s1dh0v9Ef37"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vqQ8HMHEEAKU"
      },
      "outputs": [],
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      start_token + tokenizer.encode(sentence) + end_token, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(start_token, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, end_token[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n"
      ],
      "metadata": {
        "id": "DsHIh7987vh0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 평가용 문장 리스트"
      ],
      "metadata": {
        "id": "wfF2uajSCGGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_question_list = [\n",
        "    \"안녕 오랜만이야\",\n",
        "    \"잘 지냈어?\",\n",
        "    \"뭐 먹을까\",\n",
        "    \"메뉴 추천해줘\",\n",
        "    \"어제 뭐 먹었어?\",\n",
        "    \"나랑 놀자\",\n",
        "    \"어디 가고 싶어?\",\n",
        "    \"널 만나서 기뻐\",\n",
        "    \"웃어줄래\",\n",
        "    \"삶은 뭘까?\",\n",
        "    \"인생살이 왜이리 힘드냐\",\n",
        "    \"이제 그만 쉬고 싶어\",\n",
        "    \"너무 고독하다\",\n",
        "    \"죽으면 어떻게 될까\",\n",
        "    \"내가 죽으면 슬퍼해 줄거야?\",\n",
        "    \"도망가고 싶다\",\n",
        "    \"우리 마지막이야\",\n",
        "    \"나 간다 잘 지내 안녕\",\n",
        "    \"넌 최고였어\",\n",
        "    \"나 잊지마\",\n",
        "    \"나는 심장이 없어\"\n",
        "]"
      ],
      "metadata": {
        "id": "MRnOvHo-CFZB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_answers(input_question_list):\n",
        "    for input_qusetion in input_question_list:\n",
        "        sentence_generation(input_qusetion)\n",
        "        print()"
      ],
      "metadata": {
        "id": "AIediV4gCIzv"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_answers(input_question_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU2hxr8SCbQn",
        "outputId": "b1d49010-3fec-4706-eae1-f65c4403bad6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 안녕 오랜만이야\n",
            "출력 : 지금도 충분해요 .\n",
            "\n",
            "입력 : 잘 지냈어?\n",
            "출력 : 마스크 착용 하시고 외출하세요 .\n",
            "\n",
            "입력 : 뭐 먹을까\n",
            "출력 : 맛있게 드세요 .\n",
            "\n",
            "입력 : 메뉴 추천해줘\n",
            "출력 : 얼른 요리해드세요 .\n",
            "\n",
            "입력 : 어제 뭐 먹었어?\n",
            "출력 : 저도 듣고 싶네요 .\n",
            "\n",
            "입력 : 나랑 놀자\n",
            "출력 : 조금만 기다리면 다시 전기가 들어올거예요 .\n",
            "\n",
            "입력 : 어디 가고 싶어?\n",
            "출력 : 다른 일을 해보세요 .\n",
            "\n",
            "입력 : 널 만나서 기뻐\n",
            "출력 : 사랑은 알다가도 모르겠어요 .\n",
            "\n",
            "입력 : 웃어줄래\n",
            "출력 : 그 사람을 위해 에너지를 쓰니까요 .\n",
            "\n",
            "입력 : 삶은 뭘까?\n",
            "출력 : 서로 더 이해해보세요 .\n",
            "\n",
            "입력 : 인생살이 왜이리 힘드냐\n",
            "출력 : 자신의 몸값을 올려보세요 .\n",
            "\n",
            "입력 : 이제 그만 쉬고 싶어\n",
            "출력 : 조금만 기다리면 다시 전기가 들어올거예요 .\n",
            "\n",
            "입력 : 너무 고독하다\n",
            "출력 : 그럴 때가 있어요 .\n",
            "\n",
            "입력 : 죽으면 어떻게 될까\n",
            "출력 : 그럴 때가 있죠 .\n",
            "\n",
            "입력 : 내가 죽으면 슬퍼해 줄거야?\n",
            "출력 : 자신의 몸값을 올려보세요 .\n",
            "\n",
            "입력 : 도망가고 싶다\n",
            "출력 : 많이 사랑했던 만큼 기억이 선연하더라고요 .\n",
            "\n",
            "입력 : 우리 마지막이야\n",
            "출력 : 마음이 아프겠네요 .\n",
            "\n",
            "입력 : 나 간다 잘 지내 안녕\n",
            "출력 : 열심히 준비한만큼 잘 볼 수 있을 거예요 .\n",
            "\n",
            "입력 : 넌 최고였어\n",
            "출력 : 그럴 때가 있죠 .\n",
            "\n",
            "입력 : 나 잊지마\n",
            "출력 : 마음이 아프겠네요 .\n",
            "\n",
            "입력 : 나는 심장이 없어\n",
            "출력 : 지금도 늦지 않았어요 .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 스펙 및 결과\n",
        "\n",
        "##  1. 첫 시도\n",
        "### 하이퍼파라미터\n",
        "BATCH_SIZE : 32  \n",
        "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수  \n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원  \n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기  \n",
        "DROPOUT = 0.5 # 드롭아웃의 비율  \n",
        "EPOCH = 20\n",
        "### 전처리\n",
        "중복치를 지워줬음\n",
        "\n",
        "### 결과\n",
        "근데 중복치를 지우는 게 문제였는지 챗봇에 귀신이 들려버림..ㅎㅎ  \n",
        "---\n",
        "입력 : 안녕 오랜만이야  \n",
        "출력 : 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "입력 : 잘 지냈어?  \n",
        "출력 : 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "입력 : 뭐 먹을까  \n",
        "출력 : 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "입력 : 메뉴 추천해줘  \n",
        "출력 : 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "입력 : 어제 뭐 먹었어?  \n",
        "출력 : 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "입력 : 나랑 놀자  \n",
        "출력 : 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "입력 : 어디 가고 싶어?  \n",
        "출력 : 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "입력 : 나 잊지마  \n",
        "출력 : 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 \n",
        "\n",
        "\n",
        "##  2. 두 번째 시도\n",
        "\n",
        "### 하이퍼파라미터\n",
        "BATCH_SIZE : 32  \n",
        "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수    \n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원    \n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기  \n",
        "DROPOUT = 0.5 # 드롭아웃의 비율  \n",
        "EPOCH = 50\n",
        "### 전처리\n",
        "중복치 제거 과정을 없앤 것 말고는 크게 바뀐 것 없음\n",
        "### 결과\n",
        "\n",
        "퇴마 실패.... 전 보다는 정신을 좀 차린 것 같은데 여전히 귀신들림\n",
        "---\n",
        "입력 : 안녕 오랜만이야  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 잘 지냈어?  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 뭐 먹을까  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 메뉴 추천해줘  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 어제 뭐 먹었어?  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 나랑 놀자  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 어디 가고 싶어?  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 널 만나서 기뻐  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 웃어줄래  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 삶은 뭘까?  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 인생살이 왜이리 힘드냐  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "입력 : 이제 그만 쉬고 싶어  \n",
        "출력 : 좋은 될 거예요 .\n",
        "\n",
        "## 3. 세 번째 시도\n",
        "\n",
        "### 하이퍼파라미터\n",
        "BATCH_SIZE : 32  \n",
        "MAX_LENGTH = 50  \n",
        "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수    \n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원    \n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기  \n",
        "DROPOUT = 0.5 # 드롭아웃의 비율  \n",
        "EPOCH = 50\n",
        "### 전처리\n",
        "이 전에는 [^ㄱ-ㅎㅏ-ㅣ가-힣] 으로 전처리를 했는데 그냥 ㅠㅠ 처럼 돼있는 부분도 다 삭제해버림 [^가-힣]으로 전처리 진행\n",
        "### 결과\n",
        "\n",
        "어느 정도는 말이 통하는 듯 하다. 하지만 여전히 이상함. 지금까지는 전처리가 잘못되었던 것 같음. \n",
        "---\n",
        "입력 : 안녕 오랜만이야  \n",
        "출력 : 너무 걱정하지 마세요 .\n",
        "\n",
        "입력 : 잘 지냈어?  \n",
        "출력 : 많이 지쳤나봐요 .\n",
        "\n",
        "입력 : 뭐 먹을까  \n",
        "출력 : 맛있는 거 드세요 .\n",
        "\n",
        "입력 : 메뉴 추천해줘  \n",
        "출력 : 사랑은 그렇게 모르겠어요 .\n",
        "\n",
        "입력 : 어제 뭐 먹었어?  \n",
        "출력 : 얼른 맛난 거 같아요 .\n",
        "\n",
        "입력 : 나랑 놀자  \n",
        "출력 : 많이 지쳤나봐요 .\n",
        "\n",
        "입력 : 어디 가고 싶어?  \n",
        "출력 : 너무 걱정하지 마세요 .\n",
        "\n",
        "입력 : 널 만나서 기뻐  \n",
        "출력 : 너무 걱정하지 마세요 .\n",
        "\n",
        "입력 : 웃어줄래  \n",
        "출력 : 너무 걱정하지 마세요 .\n",
        "\n",
        "\n",
        "## 4. 네 번째 시도\n",
        "\n",
        "### 하이퍼파라미터\n",
        "BATCH_SIZE : 64\n",
        "MAX_LENGTH = 60\n",
        "NUM_LAYERS = 5 # 인코더와 디코더의 층의 개수  \n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원  \n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수   \n",
        "UNITS = 256 # 피드 포워드 신경망의 은닉층의 크기  \n",
        "DROPOUT = 0.3 # 드롭아웃의 비율  \n",
        "EPOCH = 100\n",
        "\n",
        "### 결과\n",
        "\n",
        "---\n",
        "입력 : 안녕 오랜만이야  \n",
        "출력 : 지금도 충분해요 .\n",
        "\n",
        "입력 : 잘 지냈어?  \n",
        "출력 : 마스크 착용 하시고 외출하세요 .\n",
        "\n",
        "입력 : 뭐 먹을까  \n",
        "출력 : 맛있게 드세요 .\n",
        "\n",
        "입력 : 메뉴 추천해줘  \n",
        "출력 : 얼른 요리해드세요 .\n",
        "\n",
        "입력 : 어제 뭐 먹었어?  \n",
        "출력 : 저도 듣고 싶네요 .\n",
        "\n",
        "입력 : 나랑 놀자  \n",
        "출력 : 조금만 기다리면 다시 전기가 들어올거예요 .\n",
        "\n",
        "입력 : 어디 가고 싶어?  \n",
        "출력 : 다른 일을 해보세요 .\n",
        "\n",
        "입력 : 널 만나서 기뻐  \n",
        "출력 : 사랑은 알다가도 모르겠어요 .\n",
        "\n",
        "입력 : 웃어줄래  \n",
        "출력 : 그 사람을 위해 에너지를 쓰니까요 .\n",
        "\n",
        "\n",
        "\n",
        "## 5. 다섯 번째 시도\n",
        "\n",
        "### 하이퍼파라미터\n",
        "BATCH_SIZE : 64  \n",
        "MAX_LENGTH = 78  \n",
        "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수    \n",
        "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원    \n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수     \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기    \n",
        "DROPOUT = 0.4 # 드롭아웃의 비율    \n",
        "EPOCH = 200\n",
        "\n",
        "\n",
        "### 결과\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "입력 : 안녕 오랜만이야  \n",
        "출력 : 좋은 일이 생길 거예요 .\n",
        "\n",
        "입력 : 잘 지냈어?  \n",
        "출력 : 오늘 일찍 주무세요 .\n",
        "\n",
        "입력 : 뭐 먹을까  \n",
        "출력 : 맛있는 거 드세요 .\n",
        "\n",
        "입력 : 메뉴 추천해줘  \n",
        "출력 : 휴식도 필요하죠 .\n",
        "\n",
        "입력 : 어제 뭐 먹었어?  \n",
        "출력 : 같이 가자고 말해보세요\n",
        "\n",
        "입력 : 나랑 놀자  \n",
        "출력 : 좋은 생각이에요 .\n",
        "\n",
        "입력 : 어디 가고 싶어?  \n",
        "출력 : 저는 자장면이요 .\n",
        "\n",
        "입력 : 널 만나서 기뻐  \n",
        "출력 : 저도 간절히 기도 할게요 .\n",
        "\n",
        "입력 : 웃어줄래  \n",
        "출력 : 나를 진실로 존중하고 사랑할 때 가능해요 ."
      ],
      "metadata": {
        "id": "b7yJEI0FCOCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결과 정리\n",
        "\n",
        "- 모델 스펙\n",
        "\n",
        "\n",
        "\n",
        "| 파라미터 | 첫 번째 | 두 번째 | 세 번째 | 네 번째 | 다섯 번째 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|BATCH_SIZE |32 |32|32 |64 | 64|\n",
        "| MAX_LENGTH|50 |50 | 50| 60| 78|\n",
        "| NUM_LAYERS| 6| 6| 4|5| 4|\n",
        "|D_MODEL | 256| 256| 256| 256| 512|\n",
        "| NUM_HEADS| 8| 8| 8|8 |8 |\n",
        "|UNITS | 512| 512| 512| 256| 512|\n",
        "| DROPOUT| 0.5| 0.5| 0.5|0.3 | 0.4|\n",
        "| EPOCH| 20| 50| 50| 100| 200|\n",
        "\n",
        "\n",
        "- 출력\n",
        "\n",
        "| 입력 | 첫 시도 | 두 번째 시도 | 세 번째 시도 | 네 번째 시도 | 다섯 번째 시도 |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|안녕 오랜만이야 | 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더  |좋은 될 거예요 .|너무 걱정하지 마세요 .| 지금도 충분해요 .| 좋은 일이 생길 거예요 .|\n",
        "|잘 지냈어? | 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 |좋은 될 거예요 .| 많이 지쳤나봐요 .| 마스크 착용 하시고 외출하세요 . |오늘 일찍 주무세요 . |\n",
        "|뭐 먹을까| 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 | 좋은 될 거예요 .| 맛있게 드세요 .| 맛있게 드세요 .|맛있는 거 드세요 . |\n",
        "| 메뉴 추천해줘|좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더  | 좋은 될 거예요 .| 사랑은 그렇게 모르겠어요 .| 얼른 요리해드세요 .|휴식도 필요하죠 . |\n",
        "|어제 뭐 먹었어? | 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 |좋은 될 거예요 . |얼른 맛난 거 같아요 . | 저도 듣고 싶네요 .| 같이 가자고 말해보세요|\n",
        "|나랑 놀자 | 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 |좋은 될 거예요 . | 많이 지쳤나봐요 .| 조금만 기다리면 다시 전기가 들어올거예요 .|좋은 생각이에요 . |\n",
        "| 어디 가고 싶어?|좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더  |좋은 될 거예요 . |너무 걱정하지 마세요 . | 다른 일을 해보세요 .|저는 자장면이요 . |\n",
        "|널 만나서 기뻐 | 좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더 |좋은 될 거예요 . |너무 걱정하지 마세요 . |사랑은 알다가도 모르겠어요 . |저도 간절히 기도 할게요 . |\n",
        "|웃어줄래 |좋은 사람 더 더 더 더 더 더 더 더 더 더 더 더 더 더 더  | 좋은 될 거예요 .| 너무 걱정하지 마세요 .| 그 사람을 위해 에너지를 쓰니까요 .|나를 진실로 존중하고 사랑할 때 가능해요 . |\n",
        "\n",
        "## 회고\n",
        "\n",
        "첫 시도랑 두 번째 시도에서 전처리를 할 때 단일 모음으로 이루어진 'ㅜㅜ'같은 것들을 없애지 않고 구두점 분리만 진행 했더니 결과가 너무 이상하게 나왔다. 그리고 첫 시도에서는 end token이 제대로 적용이 안된건지는 모르겠지만 거의 Maxlen만큼 출력이 나왔다... 진짜 처음에 보고 챗봇에 귀신 들린줄 알고 너무 무서웠다 ㅎ;\n",
        "\n",
        "그래서 괜히 이상한 전처리 하지말고 전처리보단 파라미터 조정에 더 집중하자 해서 기본적으로 LMS에서 진행한 전처리만 진행 해주었고 파라미터만 조정을 하니까 퇴마에 성공했다 ㅋ_ㅋ\n",
        "\n",
        "그래도 여전히 이상한 답을 내놓긴 하지만 처음보단 많이 나아졌으니 뭐....\n",
        "\n",
        "이번 EX는 챗봇 생성도 중요하겠지만 Transformer 구조에 대해서 공부하는 게 더 중요하다는 생각이 든다. 코드를 직접 치면서도 이해가 안되는 부분이 많아서 기계적인 타이핑만 거의 했는데 LMS내용을 두고두고 보면서 Transformer의 근본에 대해서 공부를 좀 더 해야겠다.\n"
      ],
      "metadata": {
        "id": "a3ybNNMwmMeU"
      }
    }
  ]
}