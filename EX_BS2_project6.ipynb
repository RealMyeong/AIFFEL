{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EX_BS2_project6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ctxaoDY1cDbqeRLHyEcWCzJrTPnf2UlC",
      "authorship_tag": "ABX9TyMPcG3kBrsAzvxAWWEa8MXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RealMyeong/Aiffel_Exploration/blob/main/EX_BS2_project6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. 데이터 다운로드"
      ],
      "metadata": {
        "id": "PWIWJppmti6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 직접 다운로드 받아서 구글 드라이브에 저장함"
      ],
      "metadata": {
        "id": "008idEC5vxRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. 데이터 읽어오기"
      ],
      "metadata": {
        "id": "z4FTlvystn4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "txt_file_path = '/content/drive/MyDrive/AIFFEL/EX/6. 작사가 만들기/data/lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "#여러개의 txt파일을 모두 읽어서 row_corpus에 저장\n",
        "for txt_file in txt_list:\n",
        "  with open(txt_file, 'r') as f:\n",
        "    raw = f.read().splitlines()\n",
        "    raw_corpus.extend(raw)\n",
        "\n",
        "print('데이터 크기: ',len(raw_corpus))\n",
        "print('Examples:\\n', raw_corpus[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXubHEa5vYJo",
        "outputId": "aee50c86-87c4-4eab-87ed-0b3841572ade"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기:  187088\n",
            "Examples:\n",
            " ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3. 데이터 정제\n",
        "\n",
        "앞서 배운 테크닉들을 활용해 문장 생성에 적합한 모양새로 데이터를 정제하세요!\n",
        "\n",
        "preprocess_sentence() 함수를 만든 것을 기억하시죠? 이를 활용해 데이터를 정제하도록 하겠습니다.\n",
        "\n",
        "추가로 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거합니다. 너무 긴 문장은 노래 가사 작사하기에 어울리지 않을 수도 있겠죠.\n",
        "그래서 이번에는 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기 를 권합니다."
      ],
      "metadata": {
        "id": "1DnpWWeFtq_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "def preprocess_sentence(s):\n",
        "  s = s.lower().strip() #1 문장을 소문자로 바꾸고 양쪽 공백을 지움\n",
        "  s = re.sub(r\"([?.!,¿])\", r\" \\1\", s) #2 특수 문자 양쪽에 공백을 넣음\n",
        "  s = re.sub(r'[\" \"]+', \" \", s) #3 여러개의 공백을 하나의 공백으로 바꿈\n",
        "  s = re.sub(r'[^a-zA-Z?.!,¿]+', ' ', s) #4 a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿈\n",
        "  s = s.strip() #5 양쪽 공백을 지움\n",
        "  s = '<start> '+s+' <end>' #6 문장 시작에 <start> 끝에 <end> 넣어줌\n",
        "  return s"
      ],
      "metadata": {
        "id": "ibbXY01Lw_5I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 여기에 정제된 문장을 모을겁니다\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # 정제를 하고 담아주세요\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보죠\n",
        "corpus[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oKjZXQbFzmZP",
        "outputId": "1e31ed63-81ca-4746-8a47-d51cacfefb54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> made my way into the night <end>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=15000,\n",
        "                                                    filters=' ',\n",
        "                                                    oov_token='<unk>')\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  tensor = tokenizer.texts_to_sequences(corpus)\n",
        "  tensor_2 = []\n",
        "  print(tensor[0])\n",
        "  for i in range(len(tensor)): #토큰 개수가 15개 이하만 가져옴\n",
        "    if len(tensor[i]) <= 15:\n",
        "      tensor_2.append(tensor[i])\n",
        "\n",
        "  tensor_2 = tf.keras.preprocessing.sequence.pad_sequences(tensor_2, padding='post')\n",
        "  \n",
        "\n",
        "      \n",
        "  print(tensor_2, tokenizer)\n",
        "  return tensor_2, tokenizer\n",
        "\n",
        "tensor_2, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmI_wXds0-nn",
        "outputId": "5be7a73a-f756-4867-9d6e-7a900334b0c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 303, 28, 99, 4825, 3]\n",
            "[[  2 303  28 ...   0   0   0]\n",
            " [  2 221  13 ...   0   0   0]\n",
            " [  2  24  17 ...   0   0   0]\n",
            " ...\n",
            " [  2   3   0 ...   0   0   0]\n",
            " [  2   3   0 ...   0   0   0]\n",
            " [  2   3   0 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7fe294baa250>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tensor_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJn4YV_L2xxn",
        "outputId": "859cad8b-df2a-4a93-a7da-f7f1d46b03ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6r69AxTUNLw",
        "outputId": "39c1d113-d2bb-4f08-e13b-2f63b956da8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156074, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUCb0_kO3z61",
        "outputId": "774f4df5-e07f-43fa-fb4a-a9ad52dfa0cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : to\n",
            "10 : a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성\n",
        "src_input = tensor_2[:, :-1]  \n",
        "\n",
        "# tensor에서 <start>를 잘라내서 타겟 문장을 생성\n",
        "tgt_input = tensor_2[:, 1:]    \n",
        "\n",
        "print((src_input).shape)\n",
        "print((tgt_input).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtZmv1667TWL",
        "outputId": "07cf13b7-75ca-408d-b03e-95d77eb2a065"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(156074, 14)\n",
            "(156074, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4. 평가 데이터셋 분리\n",
        "\n",
        "훈련 데이터와 평가 데이터를 분리하세요!\n",
        "\n",
        "tokenize() 함수로 데이터를 Tensor로 변환한 후, sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리하도록 하겠습니다. 단어장의 크기는 12,000 이상 으로 설정하세요! 총 데이터의 20% 를 평가 데이터셋으로 사용해 주세요!"
      ],
      "metadata": {
        "id": "EEKVmIENtuEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(src_input,\n",
        "                                                    tgt_input,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 27)"
      ],
      "metadata": {
        "id": "nMJ2whjmXged"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5. 인공지능 만들기"
      ],
      "metadata": {
        "id": "jolOIPrbt4sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        " # tokenizer가 구축한 단어사전 내 15000개와, 여기 포함되지 않은 0:<pad>를 포함하여 15001개\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만듦\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSD1iUZJYdu5",
        "outputId": "813d857c-f9f7-4b1e-ed27-bc3940103596"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_3 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.rnn_3(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 512\n",
        "hidden_size = 1024\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "2tDvBxnkYxIK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
        "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "model(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHwH6U35Y2sn",
        "outputId": "c2ca3ff0-1fc9-4a25-8341-8bbf9ac5a6b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 15001), dtype=float32, numpy=\n",
              "array([[[-4.73902037e-05,  2.18599962e-05, -5.16655155e-06, ...,\n",
              "         -6.23064188e-05, -3.35342884e-06, -4.60978208e-06],\n",
              "        [-1.01163838e-04,  1.10990506e-04,  2.56117874e-05, ...,\n",
              "         -1.23248275e-04,  4.54557921e-05,  1.28942493e-05],\n",
              "        [-9.78249736e-05,  2.46599404e-04,  7.26079234e-05, ...,\n",
              "         -1.84746285e-04,  1.33556736e-04,  6.33578238e-05],\n",
              "        ...,\n",
              "        [ 2.32638326e-04, -6.20293897e-04, -7.16078444e-04, ...,\n",
              "         -4.02541016e-04,  7.66858226e-04, -1.23077445e-03],\n",
              "        [ 1.55132817e-04, -7.73789769e-04, -9.52937815e-04, ...,\n",
              "         -4.39250260e-04,  8.77662504e-04, -1.53662753e-03],\n",
              "        [ 6.24772292e-05, -9.10923351e-04, -1.19054900e-03, ...,\n",
              "         -4.67473437e-04,  9.79109202e-04, -1.83556241e-03]],\n",
              "\n",
              "       [[-4.73902037e-05,  2.18599962e-05, -5.16655155e-06, ...,\n",
              "         -6.23064188e-05, -3.35342884e-06, -4.60978208e-06],\n",
              "        [-1.25385573e-04,  4.15759096e-05,  1.10044566e-05, ...,\n",
              "         -1.36746108e-04,  7.48519460e-06,  1.75628338e-05],\n",
              "        [-2.07428486e-04,  9.33919091e-06,  3.83613842e-05, ...,\n",
              "         -2.02363139e-04,  7.40393079e-05,  7.52740671e-05],\n",
              "        ...,\n",
              "        [-8.70661112e-04, -5.78932522e-04,  4.82583600e-05, ...,\n",
              "         -1.08516077e-03,  4.05095838e-04,  7.10963155e-04],\n",
              "        [-7.57790636e-04, -7.03618396e-04,  1.35350583e-05, ...,\n",
              "         -1.08767161e-03,  3.64896987e-04,  6.50241855e-04],\n",
              "        [-6.35738717e-04, -8.58113752e-04, -5.10445316e-05, ...,\n",
              "         -1.11272477e-03,  3.35415971e-04,  5.25162381e-04]],\n",
              "\n",
              "       [[-4.73902037e-05,  2.18599962e-05, -5.16655155e-06, ...,\n",
              "         -6.23064188e-05, -3.35342884e-06, -4.60978208e-06],\n",
              "        [-1.55464833e-04,  2.21117716e-05, -3.46340494e-06, ...,\n",
              "         -1.61594522e-04, -3.14099052e-05,  1.93440846e-05],\n",
              "        [-2.45423696e-04, -4.08288652e-05,  1.19905671e-05, ...,\n",
              "         -2.27195298e-04, -9.37784862e-05,  1.91241325e-05],\n",
              "        ...,\n",
              "        [-2.51208432e-04,  2.59603432e-04, -2.25854907e-04, ...,\n",
              "         -9.19752289e-04, -3.56614328e-04, -3.25307745e-04],\n",
              "        [-1.93874163e-04,  1.87479833e-04, -3.26182228e-04, ...,\n",
              "         -9.77997319e-04, -3.26954701e-04, -4.66012803e-04],\n",
              "        [-1.49003012e-04,  7.44775170e-05, -4.64988640e-04, ...,\n",
              "         -1.02014258e-03, -2.47936347e-04, -6.57681376e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-4.73902037e-05,  2.18599962e-05, -5.16655155e-06, ...,\n",
              "         -6.23064188e-05, -3.35342884e-06, -4.60978208e-06],\n",
              "        [-1.06985681e-04,  1.66216341e-05,  2.03850486e-05, ...,\n",
              "         -1.69307285e-04,  7.13079953e-06,  4.79518858e-05],\n",
              "        [-1.43746016e-04, -2.49113946e-05,  5.10992795e-05, ...,\n",
              "         -2.78735301e-04, -4.33930363e-05,  8.28229677e-05],\n",
              "        ...,\n",
              "        [ 5.97475264e-06, -1.43106282e-03, -8.78694002e-04, ...,\n",
              "         -7.15982576e-04,  1.40094535e-05, -4.56684415e-04],\n",
              "        [-7.02296456e-05, -1.54844159e-03, -1.07354205e-03, ...,\n",
              "         -7.15621980e-04,  1.96480090e-04, -8.03205825e-04],\n",
              "        [-1.54271853e-04, -1.63846277e-03, -1.27130875e-03, ...,\n",
              "         -7.04654900e-04,  3.73779476e-04, -1.16306928e-03]],\n",
              "\n",
              "       [[-4.73902037e-05,  2.18599962e-05, -5.16655155e-06, ...,\n",
              "         -6.23064188e-05, -3.35342884e-06, -4.60978208e-06],\n",
              "        [-1.55464833e-04,  2.21117716e-05, -3.46340494e-06, ...,\n",
              "         -1.61594522e-04, -3.14099052e-05,  1.93440846e-05],\n",
              "        [-2.60026922e-04,  5.65303617e-06,  3.35874647e-05, ...,\n",
              "         -2.42581606e-04, -4.34385292e-05, -3.59230785e-06],\n",
              "        ...,\n",
              "        [-7.97796820e-04, -1.14355842e-03,  6.49447378e-04, ...,\n",
              "         -4.41659271e-04,  2.51342808e-05,  4.82119649e-05],\n",
              "        [-7.11029163e-04, -1.31983345e-03,  4.59742820e-04, ...,\n",
              "         -4.96064778e-04,  5.71477831e-05, -1.32571673e-04],\n",
              "        [-6.39783684e-04, -1.47403614e-03,  2.27646568e-04, ...,\n",
              "         -5.50816767e-04,  1.27787760e-04, -3.59099213e-04]],\n",
              "\n",
              "       [[-4.73902037e-05,  2.18599962e-05, -5.16655155e-06, ...,\n",
              "         -6.23064188e-05, -3.35342884e-06, -4.60978208e-06],\n",
              "        [-1.36740811e-04,  2.08539241e-05, -1.87278201e-05, ...,\n",
              "         -1.59445641e-04, -8.35178726e-05,  2.72320995e-05],\n",
              "        [-1.96855748e-04,  6.19736820e-05, -6.84544066e-05, ...,\n",
              "         -2.58728163e-04, -1.65937847e-04,  9.37730147e-05],\n",
              "        ...,\n",
              "        [-8.26214819e-05, -6.65719272e-04, -4.80059331e-04, ...,\n",
              "         -6.35705539e-04,  4.30741900e-04, -8.38654174e-04],\n",
              "        [-1.01433885e-04, -8.37873493e-04, -6.71427173e-04, ...,\n",
              "         -6.45493274e-04,  5.65032591e-04, -1.14765076e-03],\n",
              "        [-1.33708221e-04, -9.91756911e-04, -8.78325547e-04, ...,\n",
              "         -6.47404988e-04,  6.94790331e-04, -1.45992369e-03]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqib7CeyZA7p",
        "outputId": "f7f39348-863c-4692-f080-7c4ae5d4c96b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  7680512   \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  6295552   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  15376025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 46,137,497\n",
            "Trainable params: 46,137,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=256, validation_data=(X_test, y_test), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWMH1lKGZGhW",
        "outputId": "aab1ff36-3454-4ab1-a11b-b450643be60e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "488/488 [==============================] - 79s 151ms/step - loss: 3.5397 - val_loss: 3.2034\n",
            "Epoch 2/10\n",
            "488/488 [==============================] - 72s 148ms/step - loss: 3.0783 - val_loss: 3.0378\n",
            "Epoch 3/10\n",
            "488/488 [==============================] - 72s 148ms/step - loss: 2.9465 - val_loss: 2.9672\n",
            "Epoch 4/10\n",
            "488/488 [==============================] - 72s 148ms/step - loss: 2.8554 - val_loss: 2.9094\n",
            "Epoch 5/10\n",
            "488/488 [==============================] - 76s 157ms/step - loss: 2.7766 - val_loss: 2.8601\n",
            "Epoch 6/10\n",
            "488/488 [==============================] - 76s 157ms/step - loss: 2.7036 - val_loss: 2.8204\n",
            "Epoch 7/10\n",
            "488/488 [==============================] - 76s 156ms/step - loss: 2.6365 - val_loss: 2.7874\n",
            "Epoch 8/10\n",
            "488/488 [==============================] - 76s 157ms/step - loss: 2.5741 - val_loss: 2.7581\n",
            "Epoch 9/10\n",
            "488/488 [==============================] - 72s 148ms/step - loss: 2.5145 - val_loss: 2.7348\n",
            "Epoch 10/10\n",
            "488/488 [==============================] - 76s 157ms/step - loss: 2.4571 - val_loss: 2.7088\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe294147e10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # 단어 하나씩 예측해 문장을 만듭니다\n",
        "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
        "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
        "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
        "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "IfL2FAXhiVm6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i hate\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RA1xyX97ExeG",
        "outputId": "b8e9fe31-f202-45c7-a6d0-f60df9b61915"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i hate the way you lie <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}